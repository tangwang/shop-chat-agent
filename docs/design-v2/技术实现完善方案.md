# AI 导购系统技术实现完善方案（V2）

## 1. 背景与目标

本文基于当前仓库（Node.js + Shopify + MCP + Claude）的既有实现，针对新需求给出**可落地、可分阶段上线**的技术完善方案。目标不是推翻重做，而是：

1. 保留当前 `/chat` 流式对话主链路；
2. 引入 Python + LangChain 的编排与理解能力（Orchestrator / Product Understanding / User Understanding）；
3. 通过“离线产出 + 在线编排 + 可观测日志 + LLM 评估”构建可持续演进的导购系统。

---

## 2. 现状能力与差距分析

## 2.1 现状（已具备）

- 已有店铺聊天前端与 SSE 回传机制；
- 已有 MCP 工具调用链，可做商品搜索、购物车、订单等操作；
- 已有 Prompt 体系（标准/热情）；
- 已有会话、消息、token 等数据库模型与 OAuth 流程；
- 已有商品理解离线结果文件：`product_understanding/output_logs/products_analyzed.csv`（需求中明确可直接使用）。

## 2.2 与新需求的差距

新需求要求：

- 强制“思考阶段”输出结构化计划（Orchestrator）；
- 用户理解（画像/记忆）模块，且短期用前端 mock 数据；
- 商品理解要形成“分维度归一化 + 分布概览 + 欢迎语 + 搜索服务”；
- 模块级日志可追踪（尤其 LLM 输入输出）；
- 先评估后迭代（LLM-as-judge 的评估脚本体系）；
- 运行环境切换到 Python 3.12 + LangChain（端口 6008）。

=> 因此建议采用“双栈协同”路线：

- **短期**：保持现有 Node 服务可用，新增 Python Agent 服务承载编排层；
- **中期**：对话主逻辑迁移到 Python（或 Node 调 Python orchestrator）；
- **长期**：统一模块边界与评估闭环。

---

## 3. 目标架构（推荐）

## 3.1 逻辑分层

1. **assistant（导购执行层）**
   - 负责欢迎语选择、最终对用户回复生成；
   - 输入：用户输入 + 编排结果 + 工具输出 + 上下文；
   - 输出：面向用户的自然语言回复 + 可选商品卡片。

2. **orchestrator（动态编排层）**
   - 强制先输出计划对象（JSON）；
   - 判断缺口、决定是否提问/推荐、选择工具调用链；
   - 可采用“方案一（思考块）”或“方案二（Function Calling）”。

3. **product_understanding（商品理解层）**
   - 使用已完成的 `products_analyzed.csv`；
   - 做维度统计、归一化映射、分布摘要、欢迎语候选池、检索辅助索引。

4. **user_understanding（用户理解层）**
   - 先采用前端 mock 行为数据 -> 画像 Markdown；
   - 输出长期偏好/场景偏好/约束雷区 + 行为证据；
   - 提供“更新画像”“个性化欢迎语”能力。

5. **tool adapters（技能适配层）**
   - product_search_fuzzy / precise
   - product_distribution
   - result_summarize
   - web_search_trend (Tavily)
   - outfit_advisor / compare_agent（可先规则 + LLM）

6. **evaluation（评估层）**
   - 离线回放对话集，对 Planner/Assistant 结果做 LLM 评估；
   - 指标：意图提取完整性、提问质量、推荐相关性、转化导向性、回复可读性等。

## 3.2 运行拓扑（建议）

- `web`（前端，端口 6008）
- `agent-service`（Python LangChain，编排+导购）
- `product-service`（读取离线商品分析与分布检索）
- `user-service`（mock 行为输入、画像生成与读取）
- `search-adapter`（搜索 API 对接）
- `tavily-adapter`（趋势 web 搜索）

---

## 4. 目录与模块落地建议

建议新增如下目录（与需求对齐）：

```text
.
├── assistant/
│   ├── prompts/
│   ├── orchestrator/
│   ├── runtime/
│   └── logs/
├── product_understanding/
│   ├── output_logs/
│   ├── summaries/
│   └── logs/
├── user_understanding/
│   ├── mock_data/
│   ├── profiles/
│   └── logs/
├── evaluation/
│   ├── datasets/
│   ├── rubrics/
│   ├── runners/
│   └── reports/
├── data/
│   ├── store/
│   └── cache/
├── Logs/
│   ├── assistant_*.log
│   ├── orchestrator_*.log
│   ├── product_*.log
│   ├── user_*.log
│   └── evaluation_*.log
└── scripts/
    ├── setup_conda_env.sh
    ├── start_product_module.sh
    ├── start_user_module.sh
    ├── start_agent_module.sh
    └── start_web.sh
```

> 注：本次先输出设计文档，代码实现可按阶段推进。

---

## 5. 模块 I/O 设计（核心）

## 5.1 Orchestrator 计划对象（统一 JSON）

建议采用方案二（Function Calling 风格）作为默认标准，便于后端解析执行。

```json
{
  "stage": "early|clarify|converge",
  "intent": {
    "category": null,
    "scene": [],
    "effect": [],
    "style": [],
    "audience": null,
    "budget": null,
    "size": null,
    "season": null,
    "region": null,
    "hard_constraints": []
  },
  "gap_assessment": {
    "missing_slots": [],
    "why_important": {}
  },
  "tool_plan": [
    {
      "tool": "product_dist_lookup",
      "priority": 1,
      "must": true,
      "reason": "先看本店在该意图下分布",
      "args": {}
    }
  ],
  "candidate_queries": {
    "fuzzy_slots": {"category":"","scene":"","effect":"","style":""},
    "search_queries": []
  },
  "questions_to_ask": [
    {"q": "你更希望是通勤还是日常休闲？", "options": ["通勤", "日常", "约会"]}
  ],
  "response_strategy": {
    "recommend_first_then_ask": true,
    "recommendation_count": 2,
    "info_density": "mid"
  },
  "confidence": 0.78
}
```

## 5.2 Assistant 回复对象

```json
{
  "answer_markdown": "...",
  "products": [{"id":"...","title":"..."}],
  "follow_up_questions": ["..."],
  "memory_update_suggestions": ["..."],
  "trace_id": "..."
}
```

## 5.3 User Understanding 输入输出

### 输入（前端 mock）
- 点击、加购、购买记录（最近 20）
- 搜索记录（最近 40，最近 10 条含详情）
- AI 对话压缩记录（最近 40）

### 输出
- `profile_markdown`
- `updated_at`
- `trigger_type`
- `evidence_items[]`
- `personalized_greetings[]`

## 5.4 Product Understanding 输入输出

### 输入
- `products_analyzed.csv`

### 输出
- `dimension_topk.json`（各维度 top50 词频）
- `dimension_mapping.json`（原词 -> 归一化词）
- `dimension_overview.md`（每归一化项分布+示例）
- `store_distribution_brief.md`
- `welcome_messages.json`（10条）

---

## 6. 行为策略实现建议（对齐你的导购原则）

## 6.1 三段式对话策略

1. **意图探索期（early）**
   - 先问 1-2 个“用户立场问题”；
   - 同时给临时推荐方向，不让用户空等。

2. **意图澄清期（clarify）**
   - 结合分布概览 + 模糊搜索结果缩小范围；
   - 问题聚焦“场合/风格/效果/预算/雷区”。

3. **收敛转化期（converge）**
   - 精确搜索 + 对比 + 搭配建议；
   - 输出 2-4 个候选，给出清晰理由，轻量引导下一步（加购/查看详情）。

## 6.2 “像真人导购”的提示词约束

- 必须体现：善解人意、贴心、专业、聪明；
- 禁止机械问参数（除收敛阶段必要信息）；
- 每轮最多 2 问，优先“先给价值再提问”。

---

## 7. 技能设计完善（含触发策略）

## 7.1 商品相关技能

1. `product_distribution`
   - 场景：意图宽泛时先看店铺分布；
   - 输入：维度类型 + key；
   - 输出：该维度统计、主流子类、代表商品。

2. `product_search_fuzzy`
   - 场景：有品类/场景但不够明确；
   - 输入：category/scene/effect/style；
   - 输出：多样化候选 + 简要总结。

3. `product_search_precise`
   - 场景：目标明确；
   - 输入：query；
   - 输出：topN 商品。

4. `result_summarize`
   - 对 top30 结果做满足度判断、query 改进、精选 ID。

## 7.2 增值技能

1. `outfit_advisor`
   - 触发：用户明确“搭配/整套/怎么穿”；
   - 输出：2 套方案 + 适用场景。

2. `compare_agent`
   - 触发：2-5 候选犹豫；
   - 输出：关键差异 + 适配建议。

3. `web_search_trend`（Tavily）
   - 严格触发：趋势/时效/新概念术语/用户不知道商品名；
   - 输出：外部知识摘要 + 可转化搜索词。

---

## 8. 上下文管理（Context）

## 8.1 结构

- `profile_context`（长期画像，低频更新）
- `recent_memory`（最近行为与关键事实）
- `dialogue_recent`（最近 10 轮）
- `dialogue_summary_old`（10轮前压缩）
- `store_distribution_brief`
- `season_region_context`
- `tool_outputs_recent`

## 8.2 压缩策略

- 超过 10 轮时压缩前段对话；
- 保留：用户目标、约束、已拒绝项、已推荐项、未决问题。

---

## 9. 日志与可观测性设计

## 9.1 日志原则

- 模块前缀独立文件：`assistant_`, `orchestrator_`, `product_`, `user_`, `evaluation_`；
- 每次请求生成 `trace_id`；
- LLM 输入输出必须记录（可脱敏）。

## 9.2 建议日志字段

- `timestamp`
- `trace_id`, `session_id`, `tenant_id`, `user_id`
- `module`, `action`, `latency_ms`
- `prompt_template_version`
- `tool_name`, `tool_args`, `tool_result_digest`
- `orchestrator_plan_json`
- `assistant_response_digest`
- `error_code`, `error_message`

---

## 10. 评估与测试驱动（TDD for LLM）

## 10.1 评估集构建

- 场景覆盖：
  - 意图不明确
  - 搭配建议
  - 多商品对比
  - 趋势术语解释
  - 强约束（预算/尺码/禁忌）

## 10.2 指标（建议）

- Intent Slot 完整度
- 提问质量（是否用户立场、是否过多）
- 推荐相关性
- 解释专业度
- 转化推动性
- 安全与合规（不过度承诺）

## 10.3 评估方式

- 规则检查 + LLM-as-judge（参考 LangSmith 思路）；
- 每次 prompt / 工具策略迭代都跑回归评估。

---

## 11. 分阶段实施路线图

## Phase 0（1-2 天）：文档与接口冻结
- 冻结 Orchestrator JSON schema；
- 冻结模块 I/O 契约；
- 冻结日志字段标准。

## Phase 1（3-5 天）：离线商品理解增强
- 实现 top50 词频统计、归一化映射、分布摘要、店铺分布简介、10条欢迎语生成；
- 产出标准化 JSON/Markdown 文件供在线服务读取。

## Phase 2（3-5 天）：用户理解 mock 闭环
- 前端配置 mock 行为数据；
- 一键生成画像 Markdown 与个性化欢迎语；
- 暂不做真实事件流触发。

## Phase 3（5-8 天）：Orchestrator + Assistant 双阶段调用
- 用户输入 -> Planner 输出计划 JSON；
- 执行 tool_plan；
- 注入结果 -> Assistant 生成最终回复；
- 左侧展示“编排中间结果 + 最终回复 + 商品结果”。

## Phase 4（3-5 天）：评估体系接入
- 建立 evaluation 数据集与评估脚本；
- 接入 LLM 评审并输出报告。

---

## 12. 与当前仓库集成方式（建议）

1. 短期兼容：
   - 保留现有 `app/routes/chat.jsx`；
   - 新增 Python 服务（6008）实现 planner + skills；
   - Node 通过 HTTP 调用 Python Orchestrator（或反向由 Python 接管 chat API）。

2. 前端改造：
   - 聊天左侧展示中间编排对象；
   - 增加“用户 mock 数据配置 + 更新画像 + 生成个性化欢迎语”页面。

3. 配置与密钥：
   - `TAVILY_API_KEY`
   - `DASHSCOPE_API_KEY`

4. 脚本规范：
   - `bash scripts/setup_conda_env.sh`
   - `bash scripts/start_product_module.sh`
   - `bash scripts/start_user_module.sh`
   - `bash scripts/start_agent_module.sh`
   - `bash scripts/start_web.sh`

---

## 13. 风险与规避

1. **双栈复杂度上升**：通过清晰 HTTP 契约与 trace_id 贯通降低调试成本。
2. **LLM 非确定性**：通过结构化输出 + 评估回归控制质量波动。
3. **日志敏感信息**：记录摘要与脱敏字段，原文可选落盘。
4. **工具滥调用**：在 Planner 提示词中限制 web_search / compare 触发条件。

---

## 14. 结论

你的新需求完全可以在当前项目上“增量实现”：

- 架构上以 Orchestrator 为核心补齐“先思考再回复”；
- 数据上以 Product/User 两个理解模块提供稳定上下文；
- 工程上以日志与评估保证可持续优化；
- 体验上通过“先给价值、再问关键问题”实现更像真人导购的交互风格。

